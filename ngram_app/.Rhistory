length(course_name)
names(course_category)
class(course_category)
course_category <- course_category[course_category!='Social Sciences']
length(course_category)
z=47065
length(course_name)
course_name<-course_name[1:z]
course_address<-course_address[1:z]
course_category<-course_category[1:z]
course_iffree<-course_iffree[1:z]
course_university<-course_university[1:z]
course_instructor<-course_instructor[1:z]
course_desc<-course_desc[1:z]
course_review_num<-course_review_num[1:z]
course_provider<-course_provider[1:z]
course_rating<-course_rating[1:z]
do.call(list(course_name,course_address,course_category,course_iffree,course_university,course_instructor,course_desc,course_review_num,course_provider,course_rating),lenth)
do.call(list(course_name,course_address,course_category,course_iffree,course_university,course_instructor,course_desc,course_review_num,course_provider,course_rating),length)
sapply(list(course_name,course_address,course_category,course_iffree,course_university,course_instructor,course_desc,course_review_num,course_provider,course_rating),length)
category_name[212]
category_name[212:220]
category_name[212:230]
category_name[212:240]
category_name[238]
category_name[237]
unique(course_category)
category_name[230:238]
category_name[220:238]
unique(course_category)
sessionInfo
sessionInfo()
?options(download.file.method = "wininet")
library(rvest)
library(httr)
library(XML)
curl_docs()
library(curl)
curl_fetch_memory
?with_config(use_proxy(...),
)
shiny::runApp('Desktop/R_wd/Coursera/Developing Data Product/Developing_Data_Product/kmeans_app')
- Now with the app we can compare the outputs interactively
- We need to run following code multiple times, include/exclude different variables and clusters to compare the output if without the app
- We need to run following code multiple times, include/exclude different variables and clusters to compare the output if without the app
- Now with the app we can compare the outputs interactively
```{r}
plotcluster(mtcars, kmd$cluster)
```
Clustering Data Product Pitch Presentation Slides
library(gridExtra)
?grid.arrange
library(fpc)
library(gridExtra)
kmd<-kmeans(x = mtcars,centers = 5);kmd2<-kmeans(x = mtcars,centers = 4)
plt1<-plotcluster(mtcars, kmd$cluster)
plt2<-plotcluster(mtcars, kmd2$cluster)
grid.arrange(plt1,plt2,ncol=2)
?grid.arrange
plt1
plt1<-plotcluster(mtcars, kmd$cluster)
plt2<-plotcluster(mtcars, kmd2$cluster)
plt1
plt2
plot(plt1)
-plotcluster(mtcars, kmd$cluster)
plotcluster(mtcars, kmd$cluster)
kgplt<-plotcluster(mtcars, kmd$cluster)
kgplt
kgplt
plotcluster(mtcars, kmd2$cluster)
plotcluster(mtcars, kmd$cluster)
kmd<-kmeans(x = mtcars,centers = 5);kmd2<-kmeans(x = mtcars,centers = 4)
p1=plotcluster(mtcars, kmd$cluster)
p2=plotcluster(mtcars, kmd2$cluster)
print(p1)
setwd('Desktop/R_wd/Coursera/Capstone Project/ngram_app/')
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
?icon()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
getwd()
sum_data = fread('sum_data.csv')
ngpred = function(query,data,rec_num){
source('n_gram core function.R')
data = sum_data
pred_words = ng_pred(data,query)
num = min(rec_num,nrow(pred_words))
pred_words[1:num,]
}
ngpred(query = "becau",sum_data,rec_num = 5)
ngpred(query = "i like",sum_data,rec_num = 5)
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
?valueBox
shiny::runApp()
shiny::runApp()
?renderText
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
?valueBox
shiny::runApp()
setwd('..')
query='I like'
sum_data = fread('sum_data.csv')
pred_data=sum_data
query = tolower(query)
query = str_trim(gsub( "[^[:alnum:]' -]", "", query ))
query_len = length(unlist(strsplit(query,' ')))
require_len = min(3,query_len)
query = paste(unlist(strsplit(query,' '))[(query_len-require_len+1):query_len],collapse = ' ')
query = str_trim(query)
goodrows=with(pred_data, grepl(paste('^',query,' [a-z]*?$',sep=''), pred_data$term, perl=TRUE))
goodrows
match_list = sum_data[goodrows]
while (nrow(match_list)==0 && nchar(query)!=0 ){
query = paste(unlist(strsplit(query,' '))[-1],collapse = ' ')
print (query)
goodrows=with(pred_data, grepl(paste('^',query,' [a-z]*?$',sep=''), pred_data$term, perl=TRUE))
match_list = sum_data[goodrows]
print(match_list)
#best_rec = array(data = 1)
#names(best_rec) = 'and'
}
wt_data = match_list
#extract the words after query for recommendation
wt_data$term = sub(paste('.*?',query,sep = ''), "", wt_data$term)
wt_data$term = gsub('[^[:alpha:]]','',wt_data$term)
wt_data$term = str_trim(wt_data$term)
# don't need those 1 character recommendations
wt_data=wt_data[which(nchar(wt_data$term)>1)]
##combine same cols and add nums
## then divide by the total
wt_data$sum_data = wt_data$sum_data/sum(wt_data$sum_data)
wt_data$sum_data = round(wt_data$sum_data,5)
# based on number of frequency to sort again
best_rec = arrange(wt_data,desc(sum_data))
best_rec = best_rec[which(best_rec$term != '')]
best_rec = best_rec[which(best_rec$sum_data!=0)]
best_rec = best_rec[nchar(best_rec$term)<10]
best_rec = best_rec[nchar(best_rec$term)>2]
if (nrow(best_rec)>1){
good_names = remove_stopwords(best_rec$term,stopwords('english'))
good_names = remove_stopwords(best_rec$term,stopwords('SMART'))
if (length(good_names)>0){
best_rec = best_rec[which(best_rec$term %in% good_names)]
}
}
if (nrow(best_rec)==0){
best_rec = array(data = 1)
names(best_rec) = 'and'
}
names(best_rec) = c('suggestion','score')
best_rec
query
class(pred_data)
head(pred_data$term)
head(pred_data)
a=pred_data[1:100,]
a
setkey(a,V1,V2)
setkey(a,V1)
a$V1 = rep(1:nrow(a))
a
rep(1:nrow(a))
a
setkey(a,V1)
a
sum_data = fread('sum_data.csv')
sum_data$V1 = rep(1:nrow(sum_data))
head(sum_data)
setkey(sum_data,V1)
a
setkey(a,term)
a
sum_data = fread('sum_data.csv')
setkey(sum_data,term)
head(sum_data)
a
sum_data = fread('sum_data.csv')
head(sum_data)
setkey(sum_data,term)
head(sum_data)
data[1:100,]
data[1:100]
sum_data[1:100,]
sum_data = fread('sum_data.csv')
ngpred = function(query,data,rec_num){
source('n_gram core function.R')
data = sum_data
pred_words = ng_pred(data,query)
num = min(rec_num,nrow(pred_words))
pred_words[1:num,]
}
ngpred(query = "i like",sum_data,rec_num = 5)
system.time(ngpred(query = "i like",sum_data,rec_num = 5))
ngpred = function(query,data,rec_num){
source('n_gram core function.R')
data = sum_data
pred_words = ng_pred(data,query)
num = min(rec_num,nrow(pred_words))
pred_words[1:num,]
}
system.time(ngpred(query = "i like",sum_data,rec_num = 5))
Q
pred_data=sum_data
query = tolower(query)
query = str_trim(gsub( "[^[:alnum:]' -]", "", query ))
query_len = length(unlist(strsplit(query,' ')))
require_len = min(3,query_len)
query = paste(unlist(strsplit(query,' '))[(query_len-require_len+1):query_len],collapse = ' ')
query = str_trim(query)
query
goodrows=with(pred_data, grepl(paste('^',query,' [a-z]*?$',sep=''), pred_data$term, perl=TRUE))
reg=paste('^',query,' [a-z]*?$',sep='')
pred_data[grep(reg, term)]
goodrows1=with(pred_data, grepl(paste('^',query,' [a-z]*?$',sep=''), pred_data$term, perl=TRUE))
reg=paste('^',query,' [a-z]*?$',sep='')
goodrows2 = pred_data[grep(reg, term)]
goodrows1
goodrows2
match_list = sum_data[goodrows1]
match_list
system.time(with(pred_data, grepl(paste('^',query,' [a-z]*?$',sep=''), pred_data$term, perl=TRUE)))
reg=paste('^',query,' [a-z]*?$',sep='')
system.time(pred_data[grep(reg, term)])
reg=paste('^',query,' [a-z]*?$',sep='')
system.time(with(pred_data, grepl(paste('^',query,' [a-z]*?$',sep=''), pred_data$term, perl=TRUE)))
system.time(pred_data[grep(reg, term)])
ngpred = function(query,data,rec_num){
source('n_gram core function.R')
data = sum_data
pred_words = ng_pred(data,query)
num = min(rec_num,nrow(pred_words))
pred_words[1:num,]
}
ngpred(query = "i like",sum_data,rec_num = 5)
sum_data = fread('sum_data.csv')
sum_data$id = sum_data$term
head(sum_data)
setkey(sum_data,id)
head(sum_data)
View(head(sum_data))
sum_data = fread('sum_data.csv')
setkey(sum_data,term)
head(sum_data)
sum_data$term = gsub('[:digit:]','',x = sum_data$term)
head(sum_data)
paste('^',query,' [a-z]*?$',sep='')
ngpred = function(query,data,rec_num){
source('n_gram core function.R')
data = sum_data
pred_words = ng_pred(data,query)
num = min(rec_num,nrow(pred_words))
pred_words[1:num,]
}
ngpred(query = "i like",sum_data,rec_num = 5)
Q
ngpred = function(query,data,rec_num){
source('n_gram core function.R')
data = sum_data
pred_words = ng_pred(data,query)
num = min(rec_num,nrow(pred_words))
pred_words[1:num,]
}
ngpred(query = "i like",sum_data,rec_num = 5)
ngpred = function(query,data,rec_num){
source('n_gram core function.R')
data = sum_data
pred_words = ng_pred(data,query)
num = min(rec_num,nrow(pred_words))
pred_words[1:num,]
}
ngpred(query = "i like",sum_data,rec_num = 5)
sum_data = fread('sum_data.csv')
ngpred = function(query,data,rec_num){
source('n_gram core function.R')
data = sum_data
pred_words = ng_pred(data,query)
num = min(rec_num,nrow(pred_words))
pred_words[1:num,]
}
ngpred(query = "i like",sum_data,rec_num = 5)
with(pred_data, grepl(reg, pred_data$term, perl=TRUE))
sum_data %>% filter(grepl(reg, y))
sum_data %>% filter(grepl(reg, term))
sum_data[with(pred_data, grepl(reg, pred_data$term, perl=TRUE))]
system.time(sum_data[with(pred_data, grepl(reg, pred_data$term, perl=TRUE))])
system.time(sum_data %>% filter(grepl(reg, term)))
shiny::runApp('ngram_app')
shiny::runApp('ngram_app')
shiny::runApp('ngram_app')
setwd('..')
getwd()
setwd('Capstone Project/')
head(sum_data)
saveRDS('sum_data',file = 'sum_data.RDS')
a=readRDS('sum_data.RDS')
head(a)
a
saveRDS(sum_data,file = 'sum_data.RDS')
save(sum_data,file = 'sum_data.Rda')
a=load('sum_data.Rda')
head(a)
a
b=load('sum_data.Rda')
b
b=readRDS('sum_data.RDS')
head(b)
system.time(readRDS('sum_data.RDS'))
system.time(fread('sum_data.csv'))
?trim()
library(quanteda)
?trim()
?trim
tw= file('final/en_US/en_US.twitter.txt',open='r')
twdata = readLines(tw,warn = F)
close(tw)
news = file('final/en_US/en_US.news.txt',open='r')
newsdata= readLines(news,warn = F)
close(news)
blog = file('final/en_US/en_US.blogs.txt',open='r')
blogdata= readLines(blog,warn = F)
close(blog)
######################################## detect language and keep only English
langfilt = function(data){
library(cldr)
lang = detectLanguage(data)
lang = lang$detectedLanguage
newdata = data[which(lang=='ENGLISH')]
newdata
}
twdata2 = langfilt(twdata)
newsdata2 = langfilt(newsdata)
blogdata2 = langfilt(blogdata)
aggdata = c(twdata2,newsdata2,blogdata2)
### need more process here
basic_clean = function(data){
data = tolower(data)
data = gsub( "[^[:alnum:] ']", "", data )
data = gsub( " rt ", " ", data )
data
}
aggdata = basic_clean(aggdata)
#####
#####
#####
####
ranfunc = function(pct,data){
rand_num = rbinom(length(data),1,pct)
rand_data = data[which(rand_num==1)]
rand_data
}
randata = ranfunc(0.1,aggdata)
txtclean = function (data,ngram=2) {
profanewds = read.table(file = 'profane1.txt')
profanewds = as.character(profanewds[,1])
profanewds2 = read.table('profane2.txt')
profanewds2 = as.character(profanewds2[,1])
mydfm = dfm(data,
ignoredFeatures = c(profanewds,profanewds2),
toLower = T,
ngrams=ngram)
mydfm = trim(mydfm,minCount=2,minDoc=2)
}
# Bigram
bi_data = txtclean(randata,2)
bi_data
#Trigram
tri_data = txtclean(randata,3)
#Quadgram
quad_data = txtclean(randata,4)
############
##col_sums##
bi_sum = colSums(bi_data)
bi_sum = sort(bi_sum,decreasing = T)
names(bi_sum) = gsub('_',' ',x = names(bi_sum) )
tri_sum = colSums(tri_data)
tri_sum = sort(tri_sum,decreasing = T)
names(tri_sum) = gsub('_',' ',x = names(tri_sum) )
quad_sum = colSums(quad_data)
quad_sum = sort(quad_sum,decreasing = T)
names(quad_sum) = gsub('_',' ',x = names(quad_sum) )
sum_data = c(bi_sum,tri_sum,quad_sum)
sum_data = as.data.table(sum_data,keep.rownames = T)
names(sum_data)[1] = 'term'
head(sum_data)
write.csv(sum_data,'sum_data.csv',row.names=F)
sum_data = fread('sum_data.csv')
ngpred = function(query,data,rec_num){
source('n_gram core function.R')
data = sum_data
pred_words = ng_pred(data,query)
num = min(rec_num,nrow(pred_words))
pred_words[1:num,]
}
ngpred(query = "i like",sum_data,rec_num = 5)
shiny::runApp('ngram_app')
sum_data = fread('sum_data.csv')
ngpred = function(query,data,rec_num){
source('n_gram core function.R')
data = sum_data
pred_words = ng_pred(data,query)
num = min(rec_num,nrow(pred_words))
pred_words[1:num,]
}
ngpred(query = "i like",sum_data,rec_num = 5)
setwd("ngram_app/")
shiny::runApp()
shiny::runApp()
ngpred = function(query,data,rec_num){
source('n_gram core function.R')
data = sum_data
pred_words = ng_pred(data,query)
num = min(rec_num,nrow(pred_words))
pred_words[1:num,]
}
ngpred(query = "i like",sum_data,rec_num = 5)
ngpred(query = "i really love",sum_data,rec_num = 5)
pred_data=sum_data
query = "i really love"
query = tolower(query)
query = str_trim(gsub( "[^[:alnum:]' -]", "", query ))
query_len = length(unlist(strsplit(query,' ')))
require_len = min(3,query_len)
query = paste(unlist(strsplit(query,' '))[(query_len-require_len+1):query_len],collapse = ' ')
query = str_trim(query)
# check if query is in the term,
# if not, deleting the first element and continue search until matched
#match_list=names(pred_data)[grepl(paste('^',query,' [a-z]*?$',sep = ''),names(pred_data))]
reg=paste('^',query,' [a-z]*?$',sep='')
goodrows=with(pred_data, grepl(reg, pred_data$term, perl=TRUE))
match_list = sum_data[goodrows]
while (nrow(match_list)==0 && nchar(query)!=0 ){
query = paste(unlist(strsplit(query,' '))[-1],collapse = ' ')
print (query)
goodrows=with(pred_data, grepl(paste('^',query,' [a-z]*?$',sep=''), pred_data$term, perl=TRUE))
match_list = sum_data[goodrows]
print(match_list)
#best_rec = array(data = 1)
#names(best_rec) = 'and'
}
match_list
nrow(match_list)>0
wt_data = match_list
#extract the words after query for recommendation
wt_data$term = sub(paste('.*?',query,sep = ''), "", wt_data$term)
wt_data$term = gsub('[^[:alpha:]]','',wt_data$term)
wt_data$term = str_trim(wt_data$term)
# don't need those 1 character recommendations
wt_data=wt_data[which(nchar(wt_data$term)>1)]
##combine same cols and add nums
## then divide by the total
wt_data$sum_data = wt_data$sum_data/sum(wt_data$sum_data)
wt_data$sum_data = round(wt_data$sum_data,5)
wt_data
# based on number of frequency to sort again
best_rec = arrange(wt_data,desc(sum_data))
best_rec = best_rec[which(best_rec$term != '')]
best_rec = best_rec[which(best_rec$sum_data!=0)]
best_rec = best_rec[nchar(best_rec$term)<10]
best_rec = best_rec[nchar(best_rec$term)>2]
best_rec
best_rec$term
remove_stopwords(best_rec$term,stopwords('english'))
good_names = remove_stopwords(best_rec$term,stopwords('english'))
good_names = remove_stopwords(best_rec$term,stopwords('SMART'))
good_names
ngpred(query = "i really love",sum_data,rec_num = 5)
ngpred = function(query,data,rec_num){
source('n_gram core function.R')
data = sum_data
pred_words = ng_pred(data,query)
num = min(rec_num,nrow(pred_words))
pred_words[1:num,]
}
ngpred(query = "i really love",sum_data,rec_num = 5)
shiny::runApp()
shiny::runApp()
getwd()
sum_data = fread('sum_data.csv')
ngpred = function(query,data,rec_num){
source('n_gram core function.R')
pred_words = ng_pred(data,query)
num = min(rec_num,nrow(pred_words))
pred_words[1:num,]
}
ngpred(query = input$mytext,sum_data,rec_num = input$mynumber)
ngpred(query = 'input',sum_data,rec_num = 2)
shiny::runApp()
shiny::runApp()
shiny::runApp()
getwd()
